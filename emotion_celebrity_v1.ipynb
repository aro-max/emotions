{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "%matplotlib inline\n",
    "import mpld3\n",
    "mpld3.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'reko_StartCelebrityRecognition_099b2c11-6cd0-4769-b83c-7999b86ff6a0.json'\n",
    "with open(filename, 'r') as f:\n",
    "    dico_cel = json.load(f)\n",
    "\n",
    "filename = 'reko_StartFaceDetection_bddf07c5-32c7-4f5c-9d0e-27e4df1cb6e2.json'\n",
    "with open(filename, 'r') as f:\n",
    "    dico_face = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the surface of the intersection of 2 bounding boxes\n",
    "def getIntersectionRatio(a, b, epsilon=1e-5):\n",
    "    \"\"\" Given two boxes `a` and `b` defined as a list of four numbers:\n",
    "            [x1,y1,x2,y2]\n",
    "        where:\n",
    "            x1,y1 represent the upper left corner\n",
    "            x2,y2 represent the lower right corner\n",
    "        It returns the Intersect of Union score for these two boxes.\n",
    "\n",
    "    Args:\n",
    "        a:          (list of 4 numbers) [x1,y1,x2,y2]\n",
    "        b:          (list of 4 numbers) [x1,y1,x2,y2]\n",
    "        epsilon:    (float) Small value to prevent division by zero\n",
    "\n",
    "    Returns:\n",
    "        (float) The Intersect of Union score.\n",
    "    \"\"\"\n",
    "    # COORDINATES OF THE INTERSECTION BOX\n",
    "    x1 = max(a[0], b[0])\n",
    "    y1 = max(a[1], b[1])\n",
    "    x2 = min(a[2], b[2])\n",
    "    y2 = min(a[3], b[3])\n",
    "\n",
    "    # AREA OF OVERLAP - Area where the boxes intersect\n",
    "    width = (x2 - x1)\n",
    "    height = (y2 - y1)\n",
    "    # handle case where there is NO overlap\n",
    "    if (width<0) or (height <0):\n",
    "        return 0.0\n",
    "    area_overlap = width * height\n",
    "\n",
    "    # COMBINED AREA\n",
    "    area_a = (a[2] - a[0]) * (a[3] - a[1])\n",
    "    area_b = (b[2] - b[0]) * (b[3] - b[1])\n",
    "    area_combined = min(area_a,area_b)\n",
    "\n",
    "    # RATIO OF AREA OF OVERLAP OVER COMBINED AREA\n",
    "    iou = abs(area_overlap / (area_combined+epsilon))\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the files to list of dict\n",
    "def flattenFiles(dico_cel,dico_face):\n",
    "    # reshape the data : create a list of dictionnaries for faces \n",
    "    faces_list = []\n",
    "    tp_face_array = np.array([])\n",
    "    for idx in range(len(dico_face)):\n",
    "        for idx_f, face in enumerate(dico_face[idx]['Faces']):\n",
    "            tp = face['Timestamp']\n",
    "            #print(tp)\n",
    "            #a =input('khn')\n",
    "            face_tp = copy.copy(face['Face'])\n",
    "            #face_tp.pop('Landmarks')\n",
    "            face_tp.pop('Pose')\n",
    "            face_tp.pop('Quality')\n",
    "            face_dic = {'Timestamp' : face['Timestamp'], 'Face' : face_tp }\n",
    "            faces_list.append(face_dic)\n",
    "            tp_face_array = np.append(tp_face_array, tp)\n",
    "\n",
    "    # reshape the data : create a list of dictionnaries for celebrities\n",
    "    tp_cel_array = []\n",
    "    celebrities_list = []\n",
    "    for idx in range(len(dico_cel)):\n",
    "        for idx_c, celebrity in enumerate(dico_cel[idx]['Celebrities']):\n",
    "            tp = celebrity['Timestamp']\n",
    "            tp_cel_array = np.append(tp_cel_array, tp)\n",
    "            celebrities_list.append(celebrity)\n",
    "            \n",
    "    return(celebrities_list,faces_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the left eye position from Landmarks\n",
    "def getLeftEyePos(l_lm):\n",
    "    X_cel , Y_cel = None, None\n",
    "    for idx in range(len(l_lm)):\n",
    "        if l_lm[idx]['Type'] == 'eyeLeft':\n",
    "            X_cel , Y_cel = l_lm[idx]['X'] , l_lm[idx]['Y']\n",
    "    return(X_cel , Y_cel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes the score to merge celebrities_list and faces_list\n",
    "def mergeFacesCelebrities(celebrities_list, faces_list, threshold):\n",
    "\n",
    "    # numpy arrays\n",
    "    face_idx = np.ones(len(celebrities_list))*-1\n",
    "    face_score = np.ones(len(celebrities_list))*-1\n",
    "\n",
    "    for idx_c, celebrity in enumerate(celebrities_list):\n",
    "\n",
    "        bb_c = []\n",
    "        X_cel = None\n",
    "        Y_cel = None\n",
    "\n",
    "        # bounding box celebrity face may not exist depending on time stamps\n",
    "        if 'Face' in celebrity['Celebrity'].keys():\n",
    "            bb_c = [celebrity['Celebrity']['Face']['BoundingBox']['Left'], celebrity['Celebrity']['Face']['BoundingBox']['Top'],\n",
    "                    celebrity['Celebrity']['Face']['BoundingBox']['Left'] +\n",
    "                    celebrity['Celebrity']['Face']['BoundingBox']['Width'],\n",
    "                    celebrity['Celebrity']['Face']['BoundingBox']['Top'] + celebrity['Celebrity']['Face']['BoundingBox']['Height']]\n",
    "            # eyeLeft celebrity\n",
    "            X_cel, Y_cel = getLeftEyePos(celebrity['Celebrity']['Face']['Landmarks'])\n",
    "        else:\n",
    "            bb_c = [celebrity['Celebrity']['BoundingBox']['Left'], celebrity['Celebrity']['BoundingBox']['Top'],\n",
    "                    celebrity['Celebrity']['BoundingBox']['Left'] +\n",
    "                    celebrity['Celebrity']['BoundingBox']['Width'],\n",
    "                    celebrity['Celebrity']['BoundingBox']['Top'] + celebrity['Celebrity']['BoundingBox']['Height']]\n",
    "\n",
    "        # time stamp celebrity\n",
    "        score_face_array = np.array([])\n",
    "        idx_face_array = np.array([])\n",
    "        score_eye_left_array = []\n",
    "        dt_all = np.array([])\n",
    "\n",
    "        for idx_f, face in enumerate(faces_list):\n",
    "\n",
    "            # bounding box face\n",
    "            bb_face = [face['Face']['BoundingBox']['Left'], face['Face']['BoundingBox']['Top'],\n",
    "                       face['Face']['BoundingBox']['Left'] +\n",
    "                       face['Face']['BoundingBox']['Width'],\n",
    "                       face['Face']['BoundingBox']['Top'] + face['Face']['BoundingBox']['Height']]\n",
    "\n",
    "            #compute the aera of the Face bounding box \n",
    "            bb_face_area = face['Face']['BoundingBox']['Width'] * face['Face']['BoundingBox']['Height']\n",
    "\n",
    "            dt = celebrity['Timestamp'] - face['Timestamp']\n",
    "            X_face, Y_face = getLeftEyePos(face['Face']['Landmarks'])\n",
    "\n",
    "            # scores\n",
    "            score_face = -1\n",
    "            score_eye_left = 1\n",
    "            if abs(dt) < 1000: # only find match if the boxes are within a 1s sphere\n",
    "\n",
    "                if abs(dt) > 1 :\n",
    "                    # can be celebrity face or celebrity bounding box (larger)\n",
    "                    score_face = getIntersectionRatio(bb_face, bb_c, epsilon=1e-5)  # /abs(dt)\n",
    "                else: # in case of exact match amplify the score \n",
    "                    score_face = getIntersectionRatio(bb_face, bb_c, epsilon=1e-5)*10\n",
    "                \n",
    "                # if the landmark are present for celebrity and face\n",
    "                if None not in (X_cel, X_face, Y_cel, Y_face):\n",
    "                    # compute a normalize distance between eye of celebrity and eye of face\n",
    "                    # the normalization factor is the area of the bounding box of the face\n",
    "                    score_eye_left = np.sqrt(\n",
    "                        (X_cel - X_face)**2 + (Y_cel - Y_face)**2)/np.sqrt(bb_face_area)\n",
    "\n",
    "                dt_all = np.append(dt_all, dt)\n",
    "\n",
    "            # save the score for one face associated to one celebrity\n",
    "            if score_face > 0:\n",
    "                score_face_array = np.append(score_face_array, score_face)\n",
    "                score_eye_left_array = np.append(\n",
    "                    score_eye_left_array, score_eye_left)\n",
    "                idx_face_array = np.append(idx_face_array, idx_f)\n",
    "\n",
    "        # find the best face associated to each celecrity\n",
    "        # if no face associated to celebrity within +/- 1 go to next time stamp \n",
    "        if score_face_array.size > 0:\n",
    "\n",
    "            # for each celebrity get the closest face to get emotion\n",
    "            # the score is in [0:100]\n",
    "            # [0:10] for bounding box matching \n",
    "            # [0:10] for eyes matching \n",
    "            # so total score in [0:10]*[0:10]\n",
    "            score_tot_array = score_face_array / (score_eye_left_array + 0.1)\n",
    "\n",
    "            cel_det = np.argmax(score_tot_array)\n",
    "            face_idx[idx_c] = idx_face_array[cel_det]\n",
    "            face_score[idx_c] = score_tot_array[cel_det]\n",
    "\n",
    "    #add the emotions and features from faces to celebrity \n",
    "    #merge the face and celebrity\n",
    "    celebrities_faces_list = copy.copy(celebrities_list)\n",
    "    for idx_c, celebrity in enumerate(celebrities_list):\n",
    "        if face_score[idx_c] > threshold :\n",
    "            celebrities_faces_list[idx_c]['FaceReko'] = faces_list[face_idx[idx_c].astype(int)]['Face']    \n",
    "            celebrities_faces_list[idx_c]['FaceReko']['EmotionScore'] = face_score[idx_c]\n",
    "        else:\n",
    "            celebrities_faces_list[idx_c]['FaceReko'] = {}\n",
    "            celebrities_faces_list[idx_c]['FaceReko']['EmotionScore'] = face_score[idx_c] \n",
    "            \n",
    "    return(celebrities_faces_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genScoreCelebrity(celebrities_faces_list,name_list,emotion_list) : \n",
    "    \n",
    "    # Average score per celebrity\n",
    "    name_score = dict()\n",
    "    for name in name_list : \n",
    "        name_score[name] = dict()\n",
    "        for emotion in emotion_list:\n",
    "            name_score[name][emotion] = 0\n",
    "        name_score[name]['cpter'] = 0\n",
    "\n",
    "    for name in name_list:\n",
    "        for cel_face in celebrities_faces_list:\n",
    "            if name == cel_face['Celebrity']['Name']:\n",
    "                if 'Emotions' in cel_face['FaceReko'].keys():\n",
    "                    name_score[name]['cpter'] += 1\n",
    "                    for emotion in cel_face['FaceReko']['Emotions']:\n",
    "                        name_score[name][emotion['Type']] += emotion['Confidence']\n",
    "\n",
    "    # Generate the output dico with normalized score \n",
    "    for name in name_list:\n",
    "        cpter = name_score[name]['cpter']\n",
    "        for emotion in name_score[name]:\n",
    "            name_score[name][emotion] /= cpter\n",
    "        name_score[name]['cpter'] = cpter\n",
    "\n",
    "    return(name_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPyCharCel(name_score,name_list,emotion_list):  \n",
    "    for name in name_list:\n",
    "        emotions_size = []\n",
    "        for emotion, score in name_score[name].items():\n",
    "            if emotion in emotion_list:\n",
    "                emotions_size.append(score)\n",
    "        # Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "        labels = emotion_list\n",
    "        sizes = emotions_size\n",
    "        explode = (0.01, 0, 0, 0, 0, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "\n",
    "        fig1, ax1 = plt.subplots()\n",
    "        plt.title(name)\n",
    "        ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "                startangle=90)\n",
    "        ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of celebrities name\n",
    "def createLists(celebrities_faces_list):\n",
    "    name_set = set()\n",
    "    for cel_face in celebrities_faces_list:\n",
    "        name = cel_face['Celebrity']['Name']\n",
    "        name_set.add(name)\n",
    "    name_list = list(name_set)\n",
    "\n",
    "    # create a list of emotion name\n",
    "    emotion_list = []\n",
    "    name = list(name_set)[0]\n",
    "    for cel_face in celebrities_faces_list:\n",
    "        if name == cel_face['Celebrity']['Name']:\n",
    "            if 'Emotions' in cel_face['FaceReko'].keys():\n",
    "                for emotion in cel_face['FaceReko']['Emotions']:\n",
    "                    emotion_list.append(emotion['Type'])\n",
    "                break\n",
    "                \n",
    "    return(name_list,emotion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the files content to list of dict\n",
    "celebrities_list,faces_list = flattenFiles(dico_cel,dico_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the outputs of recognize-celebrities and get-face-detection from aws-rekognition\n",
    "# associate emotions and feature from face-detection to celebrities \n",
    "# the threshold values determines when a celebrity is detected in the faces \n",
    "# should be in [2:10]\n",
    "celebrities_faces_list = mergeFacesCelebrities(celebrities_list, faces_list,threshold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of celebrities detected and a list of emotions \n",
    "name_list,emotion_list = createLists(celebrities_faces_list)                                \n",
    "#For each celebrity computes the average of each emotion during the video\n",
    "name_score = genScoreCelebrity(celebrities_faces_list,name_list,emotion_list)\n",
    "plotPyCharCel(name_score,name_list,emotion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'celebrities_emotions.json' \n",
    "with open(filename, 'r') as f:\n",
    "    js_celebrities_faces_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js_celebrities_faces_list == celebrities_faces_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
